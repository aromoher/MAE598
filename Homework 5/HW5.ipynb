{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "SQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 = tensor([2.7367])\n",
      "x2 = tensor([2.8027])\n",
      "Objective function value = tensor([7.5285])\n"
     ]
    }
   ],
   "source": [
    "#pip install qpsolvers[open_source_solvers]\n",
    "\n",
    "import torch as t\n",
    "\n",
    "#Initializing x\n",
    "x = t.tensor([[1.], [1.]]) # x[0] = x1 and x[1] = x2\n",
    "\n",
    "#Initializing mu and W just to get calculation started -- calculated with initial conditions\n",
    "u = t.tensor([[6.], [2.]]) # u[0] = u1 and u[1] = u2\n",
    "W = t.tensor([[2., 0.], [0., (2 + 2*u[0] + 2*u[1])]]) \n",
    "w = t.abs(u) #inital weight for line search\n",
    "alpha = 1 #initial step size\n",
    "\n",
    "#Calculating Lagrange Gradient\n",
    "gL = t.tensor([[2*x[0]], [2*x[1] -6]]) + t.matmul( t.tensor([[-2., 5.], [2*x[1], (2*x[1] - 2) ]])   , u  )\n",
    "\n",
    "#While loop\n",
    "e = 0.001\n",
    "while t.norm(gL) > e:\n",
    "    #Solve for s(k), u(k+1) using QP ************************************************************************************************************\n",
    "    #I first solved the equations for the QP by hand and then put them here\n",
    "    a_W = W[0,0]\n",
    "    b_W = W[0,1]\n",
    "    c_W = W[1,0]\n",
    "    d_W = W[1,1]\n",
    "    \n",
    "    g = t.tensor([[(x[1]**2 - 2*x[0])], [((x[1] - 1)**2 + 5*x[0] -15)]])\n",
    "    g_old = g\n",
    "    A = t.tensor([[-2., 2*x[1]], [5., (2*x[1] - 2) ]])\n",
    "    A_inv = t.inverse(A)\n",
    "    fx = t.tensor([[2*x[0]], [(2*x[1] - 6)]])\n",
    "    \n",
    "    s2 = (-3.5*x[1]**2 + 7*x[1] - 5*x[0] + 14)/(7*x[1] - 2)\n",
    "    s1 = 0.5*x[1]**2 - x[1] + x[1]*s2\n",
    "    s = t.tensor([[s1], [s2]]) #s(k)\n",
    "    \n",
    "    old_u = u\n",
    "    u2 = ( -c_W*s1 - d_W*s2 -2*x[1] + 6 - a_W*s1*x[1] - 2*x[0]*x[1] - b_W*x[1]*s2  )/(7*x[1] - 2)\n",
    "    u1 = 0.5*a_W*s1 + 0.5*b_W*s2 + 2.5*u2 + x[0]\n",
    "    u = t.tensor([[u1], [u2]]) #mu(k+1)\n",
    "    \n",
    "    #Line search, alpha(k), merit function and armijo line search ********************************************************************************\n",
    "    w1 = t.abs(u) #weight option 1\n",
    "    w2 = 0.5*w + 0.5*t.abs(u) #weight option 2\n",
    "    w = t.maximum(w1, w2) #weight\n",
    "    Xm = x + alpha*s\n",
    "    Gm = t.tensor([[(Xm[1]**2 - 2*Xm[0])], [((Xm[1] - 1)**2 + 5*Xm[0] -15)]]) #constraints with x = x + alpha*s\n",
    "    oB_fun = Xm[0]**2 + (Xm[1] - 3)**2 #objective function with x = x + alpha*s\n",
    "    mF = oB_fun + w[0]*max(0, Gm[0]) + w[1]*max(0, Gm[1]) #merit function\n",
    "    \n",
    "    mA = t.tensor([[-2., 2*Xm[1]], [5., (2*Xm[1] - 2) ]])\n",
    "    mfx = t.tensor([[2*Xm[0]], [(2*Xm[1] - 6)]])\n",
    "    dg_Dalpha = t.matmul(mA, s)\n",
    "    dmF = t.matmul(t.transpose(mfx, 0, 1), s) +  w[0]*max(0, dg_Dalpha[0]) + w[1]*max(0, dg_Dalpha[1]) #derivative of merit function\n",
    "    phi = mF + alpha*dmF\n",
    "    \n",
    "    old_alpha = alpha\n",
    "    if mF > phi:\n",
    "        alpha_dum = alpha\n",
    "        alpha = alpha_dum*0.5\n",
    "    \n",
    "    #x(k+1) = x(k) + alpha(k)*s(k) **************************************************************************************************************\n",
    "    x_old = x\n",
    "    x_dum = x + alpha*s\n",
    "    x = x_dum\n",
    "    g_new = t.tensor([[(x[1]**2 - 2*x[0])], [((x[1] - 1)**2 + 5*x[0] -15)]])\n",
    "    \n",
    "    #W(k+1), BFGS *******************************************************************************************************************************\n",
    "    y = g_new - g_old\n",
    "    S = x - x_old \n",
    "    W_old = W\n",
    "    first_Term = t.matmul(y, t.transpose(y, 0, 1))/t.matmul(t.transpose(y, 0, 1),S)\n",
    "    second_Term = t.matmul(t.matmul(t.matmul(W_old, S), t.transpose(S, 0, 1)), W_old)\n",
    "    sec_dev = t.matmul(t.matmul(t.transpose(S, 0, 1), W_old),S)\n",
    "    two = (second_Term/sec_dev)\n",
    "    W = W_old + first_Term - two  \n",
    "    \n",
    "    #Calculate Lagrange Gradient ****************************************************************************************************************\n",
    "    gL = t.tensor([[2*x[0]], [2*x[1] -6]]) + t.matmul( t.tensor([[-2., 5.], [2*x[1], (2*x[1] - 2) ]])   , u  ) #need to update x and mu above\n",
    "    \n",
    "   \n",
    "objective_fun = oB_fun = x[0]**2 + (x[1] - 3)**2 \n",
    "print('x1 =', x[0])\n",
    "print('x2 =', x[1])\n",
    "print('Objective function value =', objective_fun)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "moon lander"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2d6e2acd905f85a7325b9d62875216e3aaf7a1996b68e1e27c6b306cb99bfde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
